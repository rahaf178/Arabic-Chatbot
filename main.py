import sounddevice as sd ## To record and play audio.
import numpy as np
import scipy.io.wavfile as wav
import whisper ## To convert speech to text.
import cohere ## To generate smart replies to text.
from gtts import gTTS ## To convert text to speech.
import pygame ## Used only to play MP3 audio files.
import time
import os
import tempfile


# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙƒØªØ¨Ø© cohere
co = cohere.Client("636EaZPxU1EBLwUdvcxs1hxFIjqYFtOI9KEPmMgH")  # ğŸ”‘ ØºÙŠÙ‘Ø±Ù‡Ø§ Ø¨Ù…ÙØªØ§Ø­Ùƒ

# Ø¥Ø¹Ø¯Ø§Ø¯ pygame Ù„Ù„ØµÙˆØª
pygame.init()

# Ø¥Ø¹Ø¯Ø§Ø¯ Whisper
whisper_model = whisper.load_model("base")  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ± "base" Ø¥Ù„Ù‰ "tiny" Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¯Ø§Ø¡

# Ø¯Ø§Ù„Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ø¹ Ø¥ÙŠÙ‚Ø§Ù Ø¹Ù†Ø¯ Ø§Ù„Ø³ÙƒÙˆÙ†
def record_audio(filename="input.wav", fs=44100, silence_threshold=10, max_duration=10):
     # Ù‡Ù†Ø§ ØªØ­Ø¯Ø¯ Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø§ÙŠÙƒ (1 Ù‡Ùˆ Ù…Ø«Ø§Ù„ØŒ Ø¹Ø¯Ù„ Ø§Ù„Ø±Ù‚Ù… Ø­Ø³Ø¨ Ø¬Ù‡Ø§Ø²Ùƒ)
    
    print("ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª... (ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†)")

    audio = []
    duration = 0
    silence_duration = 0
    frame_duration = 0.5  # Ù†ØµÙ Ø«Ø§Ù†ÙŠØ©
    frames_per_chunk = int(fs * frame_duration)

    while duration < max_duration:
        chunk = sd.rec(frames_per_chunk, samplerate=fs, channels=2, dtype='int16')

        sd.wait()
        volume = np.abs(chunk).mean()

        if volume > silence_threshold:
            audio.append(chunk)
            silence_duration = 0
        else:
            silence_duration += frame_duration
            if silence_duration > 1.5 and len(audio) > 0:  # ØªÙˆÙ‚Ù Ø¨Ø¹Ø¯ 1.5 Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ø³ÙƒÙˆÙ†
                break

        duration += frame_duration

    if audio:
        audio_data = np.concatenate(audio, axis=0)
        wav.write(filename, fs, audio_data)
        print("âœ… ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„.")
        return True
    else:
        print("ğŸš« Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ØµÙˆØª.")
        return False


# Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ
def transcribe_audio(audio_path):
    print("ğŸ§  ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...")
    result = whisper_model.transcribe(audio_path, language="ar")
    return result["text"].strip()

# Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯
def generate_response(user_text):
    if not user_text.strip():
        return "Ù„Ù… Ø£Ø³Ù…Ø¹ Ø´ÙŠØ¦Ù‹Ø§ ÙˆØ§Ø¶Ø­Ù‹Ø§."
    print("ğŸ¤– ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯...")
    response = co.chat(message=user_text)
    return response.text.strip()

# Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª
def speak(text):
    print("ğŸ”Š ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª...")
    tts = gTTS(text=text, lang="ar")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        temp_path = fp.name
    tts.save(temp_path)
    pygame.mixer.music.load(temp_path)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        time.sleep(0.1)
    os.remove(temp_path)

# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
def main():
    if record_audio("input.wav"):
        user_text = transcribe_audio("input.wav")
        print("ğŸ‘¤ Ø£Ù†Øª:", user_text)
        response = generate_response(user_text)
        print("ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:", response)
        speak(response)

if __name__ == "__main__":
    main()